{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d4fc1f58165e4d7d8cbaae2ae29dc617": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_37387186be5240f8ba33f5b68049e06b",
              "IPY_MODEL_b1133a12297f41228265c0be53095cb1",
              "IPY_MODEL_b6b2cf89be7b4f2cb4c37a700fce3178"
            ],
            "layout": "IPY_MODEL_6950d2d4fafd49c98bc3f33751034c01"
          }
        },
        "37387186be5240f8ba33f5b68049e06b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86029982fb2b480f982cddee24de36c9",
            "placeholder": "​",
            "style": "IPY_MODEL_06d2327561d04565a2b82a5eabf575c8",
            "value": "model.safetensors: 100%"
          }
        },
        "b1133a12297f41228265c0be53095cb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba5155b086464743a0ab206a29f3f87a",
            "max": 267954768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_423e77aea5844cfa9cd8d005914c26cc",
            "value": 267954768
          }
        },
        "b6b2cf89be7b4f2cb4c37a700fce3178": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be9ca57d2b414cfca854fa1e1a640ed5",
            "placeholder": "​",
            "style": "IPY_MODEL_0d687109c8eb41898314fcde5eee43bb",
            "value": " 268M/268M [00:01&lt;00:00, 168MB/s]"
          }
        },
        "6950d2d4fafd49c98bc3f33751034c01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86029982fb2b480f982cddee24de36c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06d2327561d04565a2b82a5eabf575c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba5155b086464743a0ab206a29f3f87a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "423e77aea5844cfa9cd8d005914c26cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "be9ca57d2b414cfca854fa1e1a640ed5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d687109c8eb41898314fcde5eee43bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Problem Statement"
      ],
      "metadata": {
        "id": "Ge1BIVjri4ha"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1NXMfKEalboZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Data Understanding (EDA)"
      ],
      "metadata": {
        "id": "fqrkLqlOi9sm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "D5x_6mmZmFx2"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Replace paths with your exact locations if needed\n",
        "fn1 = \"Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products_May19.csv\"\n",
        "fn2 = \"1429_1.csv\"\n",
        "fn3 = \"Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products.csv\"\n",
        "\n",
        "cols = ['asins', 'reviews.rating', 'name', 'brand', 'categories',\n",
        "       'reviews.text', 'reviews.title', 'reviews.username', 'reviews.numHelpful']\n",
        "# Load each, ignoring missing useful outer columns\n",
        "df1 = pd.read_csv(fn1, usecols=cols)\n",
        "df2 = pd.read_csv(fn2, usecols=cols)\n",
        "df3 = pd.read_csv(fn3, usecols=cols)\n",
        "\n",
        "df = pd.concat([df1, df2, df3], ignore_index=True)\n",
        "df.to_csv(\"amazon_reviews.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRgQrrjmnzen",
        "outputId": "85440b01-d884-4596-b431-b73a6a15277d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-28-3579109737.py:13: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df2 = pd.read_csv(fn2, usecols=cols)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "LMAB1F50MxI-"
      },
      "outputs": [],
      "source": [
        "###Import Data\n",
        "### Note:  Data is in the zip. Extract it to the folder data\n",
        "review_df=pd.read_csv(\"amazon_reviews.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "review_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTrOeVROnn4H",
        "outputId": "7e5e6472-88a6-4db2-f905-08bd8a98bbfe"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['name', 'asins', 'brand', 'categories', 'reviews.numHelpful',\n",
              "       'reviews.rating', 'reviews.text', 'reviews.title', 'reviews.username'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Exploring Missing Values and Duplicates"
      ],
      "metadata": {
        "id": "Qk-2otyunbPM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Data Preperation and Feature Engineering"
      ],
      "metadata": {
        "id": "oSb52GX_rpfj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Making dataframes for different kind of models"
      ],
      "metadata": {
        "id": "IJUKlN09r3qf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = review_df[['asins', 'reviews.rating', 'name', 'brand', 'categories',\n",
        "       'reviews.text', 'reviews.title', 'reviews.username']]\n",
        "df2 = review_df[[\"name\", \"reviews.rating\", \"reviews.text\", \"reviews.numHelpful\"]]"
      ],
      "metadata": {
        "id": "sVOuAUkjv1Et"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Dealing of Null Values and Duplicates"
      ],
      "metadata": {
        "id": "yfQ7K8x7w1r1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.1 for df1"
      ],
      "metadata": {
        "id": "c3pG8oETywoH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "review_df_cleaned=df1[~df1['reviews.text'].isnull()].copy()"
      ],
      "metadata": {
        "id": "EqG2O66cw1R2"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Removed reviews with more than > 400 words  due to token limitation of Sentence Transformers and computing\n",
        "review_df_cleaned['token_count'] = review_df_cleaned['reviews.text'].apply(lambda x: len(x.split()))\n",
        "review_df_cleaned=review_df_cleaned[review_df_cleaned['token_count']<=400]"
      ],
      "metadata": {
        "id": "OlEB1x7JxGBr"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_df_cleaned['review_sentiment']=review_df_cleaned['reviews.rating']>3"
      ],
      "metadata": {
        "id": "M4o-DHtBHgDl"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = review_df_cleaned['reviews.text'].values"
      ],
      "metadata": {
        "id": "K_xIEmxMKxz2"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.2 for df2"
      ],
      "metadata": {
        "id": "DOIsubd2y1Yf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reclassify using your rule: ≤ 3 = negative, ≥ 4 = positive\n",
        "df2[\"sentiment\"] = df2[\"reviews.rating\"].apply(\n",
        "    lambda r: \"negative\" if r <= 3 else \"positive\"\n",
        ")\n",
        "df2.to_csv(\"labeled_reviews.csv\", index=False)\n",
        "# Show counts before balancing\n",
        "counts_before = df2[\"sentiment\"].value_counts()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-pdQvnzy54x",
        "outputId": "ccceb804-ec4b-4452-f7c0-a47e62d2c030"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-34-2570520918.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df2[\"sentiment\"] = df2[\"reviews.rating\"].apply(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 Extract the top helpful reviews"
      ],
      "metadata": {
        "id": "pBrtYF9J0E-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the labeled dataset\n",
        "df2 = pd.read_csv(\"labeled_reviews.csv\")\n",
        "\n",
        "# Replace NaNs in helpful counts with 0\n",
        "df2[\"reviews.numHelpful\"] = df2[\"reviews.numHelpful\"].fillna(0)\n",
        "\n",
        "# Define how many top reviews to pick per class per product\n",
        "TOP_N = 5\n",
        "\n",
        "# Sort and group to pick\n",
        "top_reviews = (\n",
        "    df2\n",
        "    .sort_values(by=\"reviews.numHelpful\", ascending=False)\n",
        "    .groupby([\"name\", \"sentiment\"])\n",
        "    .head(TOP_N)\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "# Quick check\n",
        "print(\"Sample top helpful reviews:\")\n",
        "print(top_reviews[[\"name\", \"sentiment\", \"reviews.numHelpful\"]].head(10))\n",
        "print(\"\\nCounts per sentiment per product (first few):\")\n",
        "print(top_reviews.groupby([\"sentiment\", \"name\"]).size().unstack(fill_value=0).iloc[:, :5])\n",
        "\n",
        "# Save for LLM processing\n",
        "top_reviews.to_csv(\"top_helpful_reviews.csv\", index=False)\n",
        "print(f\"\\n✅ Top {TOP_N} helpful reviews per sentiment per product saved to 'top_helpful_reviews.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fdrcwHa0KFi",
        "outputId": "6d9de1ea-e4d7-46b2-b040-652922d58cde"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample top helpful reviews:\n",
            "                                                name sentiment  \\\n",
            "0  Fire Tablet, 7 Display, Wi-Fi, 8 GB - Includes...  positive   \n",
            "1  Fire Tablet, 7 Display, Wi-Fi, 8 GB - Includes...  positive   \n",
            "2  Amazon Kindle Lighted Leather Cover,,,\\r\\nAmaz...  negative   \n",
            "3  Fire Tablet, 7 Display, Wi-Fi, 8 GB - Includes...  positive   \n",
            "4  Oem Amazon Kindle Power Usb Adapter Wall Trave...  negative   \n",
            "5  AmazonBasics Bluetooth Keyboard for Android De...  positive   \n",
            "6  Amazon Tap Smart Assistant Alexaenabled (black...  positive   \n",
            "7  Fire Kids Edition Tablet, 7 Display, Wi-Fi, 16...  positive   \n",
            "8  AmazonBasics Bluetooth Keyboard for Android De...  positive   \n",
            "9                 Echo (White),,,\\r\\nEcho (White),,,  negative   \n",
            "\n",
            "   reviews.numHelpful  \n",
            "0               780.0  \n",
            "1               740.0  \n",
            "2               730.0  \n",
            "3               650.0  \n",
            "4               621.0  \n",
            "5               525.0  \n",
            "6               434.0  \n",
            "7               355.0  \n",
            "8               345.0  \n",
            "9               292.0  \n",
            "\n",
            "Counts per sentiment per product (first few):\n",
            "name       All-New Fire 7 Tablet with Alexa, 7\" Display, 8 GB - Marine Blue  \\\n",
            "sentiment                                                                     \n",
            "negative                                                   4                  \n",
            "positive                                                   5                  \n",
            "\n",
            "name       All-New Fire HD 8 Kids Edition Tablet, 8 HD Display, 32 GB, Blue Kid-Proof Case  \\\n",
            "sentiment                                                                                    \n",
            "negative                                                   5                                 \n",
            "positive                                                   5                                 \n",
            "\n",
            "name       All-New Fire HD 8 Kids Edition Tablet, 8 HD Display, 32 GB, Pink Kid-Proof Case  \\\n",
            "sentiment                                                                                    \n",
            "negative                                                   5                                 \n",
            "positive                                                   5                                 \n",
            "\n",
            "name       All-New Fire HD 8 Tablet with Alexa, 8 HD Display, 16 GB, Marine Blue - with Special Offers  \\\n",
            "sentiment                                                                                                \n",
            "negative                                                   5                                             \n",
            "positive                                                   5                                             \n",
            "\n",
            "name       All-New Fire HD 8 Tablet with Alexa, 8 HD Display, 32 GB, Marine Blue - with Special Offers  \n",
            "sentiment                                                                                               \n",
            "negative                                                   5                                            \n",
            "positive                                                   5                                            \n",
            "\n",
            "✅ Top 5 helpful reviews per sentiment per product saved to 'top_helpful_reviews.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Feature Selection"
      ],
      "metadata": {
        "id": "MbOc2VjA0sf7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IFiaV5tb0n54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Modeling"
      ],
      "metadata": {
        "id": "w2fdzyT30__T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1 Generate Text Embeddings (df1)\n"
      ],
      "metadata": {
        "id": "8CvfZcAe1K8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "embeddings = model.encode(review_df_cleaned['reviews.text'].values)"
      ],
      "metadata": {
        "id": "OrBdxOr41D87"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "X = embeddings\n",
        "y = review_df_cleaned['review_sentiment']\n",
        "\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
      ],
      "metadata": {
        "id": "rf-g5mfnHQic"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2 Logistic Regression Model to classify sentiment (df1)"
      ],
      "metadata": {
        "id": "gZzTrjniIJ4a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create and train logistic regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and print classification metrics\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "logistic_classification_report = classification_report(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjdqylW9IRXZ",
        "outputId": "eec11704-5324-4621-b457-fd3ccf26d797"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.78      0.31      0.44      1654\n",
            "        True       0.94      0.99      0.97     18744\n",
            "\n",
            "    accuracy                           0.94     20398\n",
            "   macro avg       0.86      0.65      0.70     20398\n",
            "weighted avg       0.93      0.94      0.92     20398\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.3 XGboost Classifier (df1)"
      ],
      "metadata": {
        "id": "kd_qpaXLIWnv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "# Create and train XGBoost classifier\n",
        "model = xgb.XGBClassifier(use_label_encoder=False)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and print metrics\n",
        "y_pred = model.predict(X_test)\n",
        "xgboost_classification_report = classification_report(y_test, y_pred)\n",
        "print(xgboost_classification_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ha9vo4UuIpKD",
        "outputId": "b11ccc8d-780b-49ca-9a53-3fde378d75c9"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:23:10] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.90      0.55      0.68      1654\n",
            "        True       0.96      0.99      0.98     18744\n",
            "\n",
            "    accuracy                           0.96     20398\n",
            "   macro avg       0.93      0.77      0.83     20398\n",
            "weighted avg       0.96      0.96      0.95     20398\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.4 Oversampling using SMOTE to make training set balanced (df1)"
      ],
      "metadata": {
        "id": "JHTBoE3-I9iu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "sm = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "# Create and train XGBoost classifier\n",
        "model = xgb.XGBClassifier(use_label_encoder=False)\n",
        "model.fit(X_resampled, y_resampled)\n",
        "print()\n",
        "\n",
        "# Predict and print metrics\n",
        "y_pred = model.predict(X_test)\n",
        "xgboost_classification_report_sampling =  classification_report(y_test, y_pred)\n",
        "print(xgboost_classification_report_sampling)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BjnCQtLJHvp",
        "outputId": "18001d9d-5db2-427d-9f71-5930a72e79ff"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:25:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.67      0.68      0.67      1654\n",
            "        True       0.97      0.97      0.97     18744\n",
            "\n",
            "    accuracy                           0.95     20398\n",
            "   macro avg       0.82      0.82      0.82     20398\n",
            "weighted avg       0.95      0.95      0.95     20398\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.5 Compute scale_pos_weight (df1)"
      ],
      "metadata": {
        "id": "4rZJCRjsJqfZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "# Compute scale_pos_weight = (# negative samples) / (# positive samples)\n",
        "ratio=review_df_cleaned['review_sentiment'].value_counts()[1]/review_df_cleaned['review_sentiment'].value_counts()[0]\n",
        "model = xgb.XGBClassifier(scale_pos_weight=ratio, use_label_encoder=False, eval_metric='logloss')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and print metrics\n",
        "y_pred = model.predict(X_test)\n",
        "xgboost_classification_report_scaled = classification_report(y_test, y_pred)\n",
        "print(xgboost_classification_report_scaled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoKr2y9xJtYP",
        "outputId": "2ae8881e-ed18-4bab-a375-8c5d5a4b2542"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-47-1916858910.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  ratio=review_df_cleaned['review_sentiment'].value_counts()[1]/review_df_cleaned['review_sentiment'].value_counts()[0]\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:28:09] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.71      0.69      0.70      1654\n",
            "        True       0.97      0.97      0.97     18744\n",
            "\n",
            "    accuracy                           0.95     20398\n",
            "   macro avg       0.84      0.83      0.84     20398\n",
            "weighted avg       0.95      0.95      0.95     20398\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.6 DistilBert Transformer Pipeline to do Classification (df2)"
      ],
      "metadata": {
        "id": "VSX6R73FKDRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Load pipeline and tokenizer\n",
        "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "\n",
        "texts = docs.tolist()\n",
        "\n",
        "labels = []\n",
        "scores = []\n",
        "\n",
        "def chunk_text(text, max_tokens=512):\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "    chunk = []\n",
        "    for word in words:\n",
        "        chunk.append(word)\n",
        "        if len(tokenizer(\" \".join(chunk))[\"input_ids\"]) >= max_tokens:\n",
        "            chunks.append(\" \".join(chunk))\n",
        "            chunk = []\n",
        "    if chunk:\n",
        "        chunks.append(\" \".join(chunk))\n",
        "    return chunks\n",
        "\n",
        "for text in texts:\n",
        "    chunks = chunk_text(text)\n",
        "    chunk_results = sentiment_pipeline(chunks, truncation=True)\n",
        "\n",
        "    # Average sentiment score; use a threshold to decide final label\n",
        "    avg_score = sum(r[\"score\"] if r[\"label\"] == \"POSITIVE\" else -r[\"score\"] for r in chunk_results) / len(chunk_results)\n",
        "    label = \"POSITIVE\" if avg_score >= 0 else \"NEGATIVE\"\n",
        "\n",
        "    labels.append(label)\n",
        "    scores.append(abs(avg_score))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Hy6S6AgKfSh",
        "outputId": "7595ed8f-9216-4f36-d830-61deb96bb4c5"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "review_df_cleaned['Predicted']=[label=='POSITIVE' for label in labels]"
      ],
      "metadata": {
        "id": "fVUV3G0cQP6F"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "report_review_sentiment = classification_report(review_df_cleaned['review_sentiment'], review_df_cleaned['Predicted'])\n",
        "print(report_review_sentiment)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dhwj0EiZQQ5n",
        "outputId": "6e979b65-6c86-432b-a5df-ce33ebd263ab"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.32      0.77      0.45      5445\n",
            "        True       0.98      0.86      0.91     62546\n",
            "\n",
            "    accuracy                           0.85     67991\n",
            "   macro avg       0.65      0.81      0.68     67991\n",
            "weighted avg       0.92      0.85      0.88     67991\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.6 Finetuned DistilBert Sentiment Classification Model (df2)"
      ],
      "metadata": {
        "id": "asnZZI59QlIY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.6.1 Tokenize the labeled sentiment"
      ],
      "metadata": {
        "id": "dhJSkhakY8yW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepares a labeled sentiment dataset (positive vs. negative).\n",
        "\n",
        "Splits and tokenizes it using DistilBERT.\n",
        "\n",
        "Saves the processed inputs and labels to disk as JSON.\n",
        "\n",
        "Saves the tokenizer for downstream use (training/inference)"
      ],
      "metadata": {
        "id": "yN8dML8FTmkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import DistilBertTokenizerFast\n",
        "import json\n",
        "\n",
        "# Load labeled data\n",
        "df = pd.read_csv(\"labeled_reviews.csv\").dropna(subset=[\"reviews.text\"])\n",
        "label_map = {\"negative\": 0, \"positive\": 1}\n",
        "df[\"label\"] = df[\"sentiment\"].map(label_map)\n",
        "\n",
        "# Split into train/test\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df[\"label\"], random_state=42)\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
        "train_enc = tokenizer(train_df[\"reviews.text\"].tolist(), truncation=True, padding=True, max_length=256)\n",
        "test_enc = tokenizer(test_df[\"reviews.text\"].tolist(), truncation=True, padding=True, max_length=256)\n",
        "\n",
        "# Convert BatchEncoding to plain dicts\n",
        "train_enc_dict = {k: v for k, v in train_enc.items()}\n",
        "test_enc_dict = {k: v for k, v in test_enc.items()}\n",
        "\n",
        "# Save as JSON\n",
        "with open(\"train_enc.json\", \"w\") as f:\n",
        "    json.dump({\"encodings\": train_enc_dict, \"labels\": train_df[\"label\"].tolist()}, f)\n",
        "\n",
        "with open(\"test_enc.json\", \"w\") as f:\n",
        "    json.dump({\"encodings\": test_enc_dict, \"labels\": test_df[\"label\"].tolist()}, f)\n",
        "\n",
        "# Save tokenizer and confirm\n",
        "tokenizer.save_pretrained(\"tokenizer\")\n",
        "print(\" Tokenized encodings and labels saved as JSON. Let's load and verify next.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvKLBWE5RBGG",
        "outputId": "d542b309-eaca-45fb-db52-358df5de3595"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Tokenized encodings and labels saved as JSON. Let's load and verify next.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.6.2 Convert to PyTorch-Ready datasets"
      ],
      "metadata": {
        "id": "FAYOHidZZKWC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This block converts the saved tokenized JSON data into PyTorch-ready datasets, which can be fed into Hugging Face's Trainer or native DataLoader loops."
      ],
      "metadata": {
        "id": "wR6PxVYaTsWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# Load JSON data\n",
        "with open(\"train_enc.json\") as f:\n",
        "    train_data = json.load(f)\n",
        "with open(\"test_enc.json\") as f:\n",
        "    test_data = json.load(f)\n",
        "\n",
        "# Define Dataset class\n",
        "class SentimentDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    def __getitem__(self, idx):\n",
        "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "# Instantiate datasets\n",
        "train_ds = SentimentDataset(train_data[\"encodings\"], train_data[\"labels\"])\n",
        "test_ds = SentimentDataset(test_data[\"encodings\"], test_data[\"labels\"])\n",
        "print(f\" Loaded datasets: {len(train_ds)} train, {len(test_ds)} test samples.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ntEXNInRk7N",
        "outputId": "3f611f84-2096-4f68-d730-440412ef5074"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Loaded datasets: 54392 train, 13599 test samples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.6.3 Create fine-tuned and balanced model using CrossEntropyLoss"
      ],
      "metadata": {
        "id": "mk8fxjVGZTxU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Added class weights to fix the severe imbalance between positive and negative reviews.\n",
        "\n",
        "Creating a fine-tuned and balanced model saved to disk and ready for inference."
      ],
      "metadata": {
        "id": "cTwW8UZfUno6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"labeled_reviews.csv\")\n",
        "counts = df[\"sentiment\"].value_counts()\n",
        "total = len(df)\n",
        "\n",
        "# Computing the class weights\n",
        "class_weights = torch.tensor(\n",
        "    [total/counts[\"negative\"], total/counts[\"positive\"]],\n",
        "    dtype=torch.float)\n",
        "\n",
        "# We create a custom trainer with the weighted loss\n",
        "class WeightedTrainer(Trainer):\n",
        "    #overriding here\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        loss_fn = nn.CrossEntropyLoss(weight=class_weights.to(logits.device)) #Uses CrossEntropyLoss(weight=class_weights) to penalize the model more for misclassifying the minority class.\n",
        "        loss = loss_fn(logits, labels)\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "\"\"\"\n",
        "Typical Hugging Face training config.\n",
        "\n",
        "Trains for 3 epochs, saves checkpoints every 500 steps, logs every 100 steps.\n",
        "\n",
        "do_train=True, do_eval=True ensure both training and evaluation occur\n",
        "\"\"\"\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"sentiment_model\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=100,\n",
        "    save_total_limit=2,\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    eval_steps=500,\n",
        "    save_steps=500\n",
        ")\n",
        "# Initializes a binary classification model (positive vs negative).\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n",
        "trainer = WeightedTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=test_ds\n",
        ")\n",
        "\n",
        "#Train\n",
        "trainer.train()\n",
        "trainer.save_model(\"sentiment_model\")\n",
        "print(\"✅ Model trained and saved successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d4fc1f58165e4d7d8cbaae2ae29dc617",
            "37387186be5240f8ba33f5b68049e06b",
            "b1133a12297f41228265c0be53095cb1",
            "b6b2cf89be7b4f2cb4c37a700fce3178",
            "6950d2d4fafd49c98bc3f33751034c01",
            "86029982fb2b480f982cddee24de36c9",
            "06d2327561d04565a2b82a5eabf575c8",
            "ba5155b086464743a0ab206a29f3f87a",
            "423e77aea5844cfa9cd8d005914c26cc",
            "be9ca57d2b414cfca854fa1e1a640ed5",
            "0d687109c8eb41898314fcde5eee43bb"
          ]
        },
        "id": "clk44juMSW1G",
        "outputId": "3952cbb2-1f3d-4485-f407-d133796dd436"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d4fc1f58165e4d7d8cbaae2ae29dc617"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmonishy1\u001b[0m (\u001b[33mmonishy1-university-of-san-diego\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.20.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250618_230645-w2nginv1</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/monishy1-university-of-san-diego/huggingface/runs/w2nginv1' target=\"_blank\">sentiment_model</a></strong> to <a href='https://wandb.ai/monishy1-university-of-san-diego/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/monishy1-university-of-san-diego/huggingface' target=\"_blank\">https://wandb.ai/monishy1-university-of-san-diego/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/monishy1-university-of-san-diego/huggingface/runs/w2nginv1' target=\"_blank\">https://wandb.ai/monishy1-university-of-san-diego/huggingface/runs/w2nginv1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10200' max='10200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10200/10200 30:11, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.572000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.538800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.589500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.501700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.517400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.462000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.487000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.407900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.468400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.429100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.554400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.485100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.391900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.571500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.431400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.466800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.410100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.474900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.469900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.450700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.467100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.473600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.422500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.459700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.487700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.415800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.349000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.473600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.351400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.374400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.430600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.415100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.379200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.438500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.390200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.348900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.310500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.315000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.296800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.331800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>0.355800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.289600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4300</td>\n",
              "      <td>0.256700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.249800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.285300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.293000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4700</td>\n",
              "      <td>0.349200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.352000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4900</td>\n",
              "      <td>0.372700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.319600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5100</td>\n",
              "      <td>0.324800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>0.317400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5300</td>\n",
              "      <td>0.351300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>0.276300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.341800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>0.302000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5700</td>\n",
              "      <td>0.255500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>0.341400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5900</td>\n",
              "      <td>0.264600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.263600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6100</td>\n",
              "      <td>0.375200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>0.293600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6300</td>\n",
              "      <td>0.309100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>0.390900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.335000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6600</td>\n",
              "      <td>0.331700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6700</td>\n",
              "      <td>0.317300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6800</td>\n",
              "      <td>0.248400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6900</td>\n",
              "      <td>0.187600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.244500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7100</td>\n",
              "      <td>0.246000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7200</td>\n",
              "      <td>0.164100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7300</td>\n",
              "      <td>0.249900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7400</td>\n",
              "      <td>0.107900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.102600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7600</td>\n",
              "      <td>0.184500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7700</td>\n",
              "      <td>0.249300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7800</td>\n",
              "      <td>0.222600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7900</td>\n",
              "      <td>0.192400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.112200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8100</td>\n",
              "      <td>0.182300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8200</td>\n",
              "      <td>0.157300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8300</td>\n",
              "      <td>0.225200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8400</td>\n",
              "      <td>0.161000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.258000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8600</td>\n",
              "      <td>0.064200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8700</td>\n",
              "      <td>0.189000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8800</td>\n",
              "      <td>0.124600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8900</td>\n",
              "      <td>0.124500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.144000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9100</td>\n",
              "      <td>0.146200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9200</td>\n",
              "      <td>0.210800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9300</td>\n",
              "      <td>0.130100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9400</td>\n",
              "      <td>0.243500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.215700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9600</td>\n",
              "      <td>0.189200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9700</td>\n",
              "      <td>0.193300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9800</td>\n",
              "      <td>0.144300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9900</td>\n",
              "      <td>0.228000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.309300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10100</td>\n",
              "      <td>0.164000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10200</td>\n",
              "      <td>0.157300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model trained and saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.6.4 Run Prediction on Test Set"
      ],
      "metadata": {
        "id": "KkB45ivwVFis"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LpSZi1RYaJ0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import json\n",
        "\n",
        "results = trainer.predict(test_ds)\n",
        "y_pred = results.predictions.argmax(axis=1)\n",
        "true_labels = [item[\"labels\"].item() for item in test_ds]\n",
        "\n",
        "classification_report_distilbert_finetuned = classification_report(\n",
        "    true_labels,\n",
        "    y_pred,\n",
        "    target_names=[\"negative\",\"positive\"],\n",
        "    output_dict=True\n",
        ")\n",
        "\n",
        "with open(\"classification_report_distilbert_finetuned.json\", \"w\") as f:\n",
        "    json.dump(classification_report_distilbert_finetuned, f, indent=4)\n",
        "\n",
        "print(\"Evaluation results:\\n\", json.dumps(classification_report_distilbert_finetuned, indent=2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "RdIzk4oSSeBW",
        "outputId": "bcec3053-6402-41f2-cb80-55565dbd6160"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation results:\n",
            " {\n",
            "  \"negative\": {\n",
            "    \"precision\": 0.8348439073514602,\n",
            "    \"recall\": 0.7661737523105361,\n",
            "    \"f1-score\": 0.7990361445783133,\n",
            "    \"support\": 1082.0\n",
            "  },\n",
            "  \"positive\": {\n",
            "    \"precision\": 0.9799301919720768,\n",
            "    \"recall\": 0.986897818966206,\n",
            "    \"f1-score\": 0.9834016638140349,\n",
            "    \"support\": 12517.0\n",
            "  },\n",
            "  \"accuracy\": 0.9693359805868078,\n",
            "  \"macro avg\": {\n",
            "    \"precision\": 0.9073870496617684,\n",
            "    \"recall\": 0.8765357856383711,\n",
            "    \"f1-score\": 0.8912189041961741,\n",
            "    \"support\": 13599.0\n",
            "  },\n",
            "  \"weighted avg\": {\n",
            "    \"precision\": 0.9683864490527807,\n",
            "    \"recall\": 0.9693359805868078,\n",
            "    \"f1-score\": 0.9687326814026039,\n",
            "    \"support\": 13599.0\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.6.5 Prepare review texts for inference"
      ],
      "metadata": {
        "id": "LKCJPxmMabpg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "setting up all raw review texts in the proper tokenized tensor format that your BERT model can understand for sentiment inference (i.e., predicting the sentiment label for each review)"
      ],
      "metadata": {
        "id": "zQm9PoAYVIAI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"amazon_reviews.csv\")\n",
        "df = df[df[\"reviews.text\"].apply(lambda x: isinstance(x, str))].copy()\n"
      ],
      "metadata": {
        "id": "cd9-KpqRV2-_"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "The reviews are processed in chunks of 1000 to avoid memory overflow.\n",
        "\n",
        "truncation=True: cuts off text beyond 256 tokens.\n",
        "\n",
        "padding=\"max_length\": pads all sequences to exactly 256 tokens.\n",
        "\n",
        "return_tensors=\"pt\": outputs PyTorch tensors.\n",
        "\n",
        "Each enc contains:\n",
        "\n",
        "input_ids: token IDs (numerical representation)\n",
        "\n",
        "attention_mask: indicates which tokens are actual text vs. padding (1 for real tokens, 0 for padding)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "from transformers import DistilBertTokenizerFast\n",
        "import torch\n",
        "\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained(\"tokenizer\")\n",
        "texts = df[\"reviews.text\"].tolist()\n",
        "\n",
        "input_ids_list, attention_masks_list = [], []\n",
        "batch_size = 1000\n",
        "\n",
        "# This loop ensures each batch of 1000 reviews is:\n",
        "\n",
        "# Tokenized into input_ids and attention_mask\n",
        "\n",
        "# Padded and truncated to 256 tokens\n",
        "\n",
        "for i in range(0, len(texts), batch_size):\n",
        "    batch = texts[i : i + batch_size]\n",
        "    enc = tokenizer(\n",
        "        batch,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=256,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    input_ids_list.append(enc[\"input_ids\"])\n",
        "    attention_masks_list.append(enc[\"attention_mask\"])\n",
        "\n",
        "# Then everything is concatenated into tensors:\n",
        "input_ids = torch.cat(input_ids_list)\n",
        "attention_masks = torch.cat(attention_masks_list)\n"
      ],
      "metadata": {
        "id": "qr7v03LJVEHg"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.6.6 Predict sentiment of all product reviews using the classifier"
      ],
      "metadata": {
        "id": "n7DkxPSAazRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To predict the sentiment (positive or negative) of all product reviews using the fine-tuned model and save the results into a new CSV.\n",
        "\n",
        "Output file: all_reviews_with_preds.csv\n",
        "\n",
        "Includes every review’s predicted sentiment.\n",
        "\n",
        "This file will later be used for aggregating sentiment per product, summarizing, or visualizing trends."
      ],
      "metadata": {
        "id": "brjEecbbWDjk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "from transformers import DistilBertForSequenceClassification\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.cuda.amp import autocast\n",
        "\n",
        "# Load model and tokenizer\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\"sentiment_model\").to('cuda').eval()\n",
        "\n",
        "#Setup Inference Pipeline\n",
        "dataset = TensorDataset(input_ids, attention_masks)\n",
        "loader = DataLoader(dataset, batch_size=128)\n",
        "\n",
        "#Running the inference pipeline\n",
        "start = time.time()\n",
        "preds = []\n",
        "with torch.no_grad():\n",
        "    for ids, masks in loader:\n",
        "        ids, masks = ids.cuda(), masks.cuda()\n",
        "        with autocast():\n",
        "            outputs = model(input_ids=ids, attention_mask=masks)\n",
        "        preds.extend(torch.argmax(outputs.logits, dim=1).tolist())\n",
        "end = time.time()\n",
        "\n",
        "print(f\"✅ Inference complete in {end - start:.2f} seconds.\")\n",
        "df[\"pred_label\"] = preds\n",
        "df[\"pred_sentiment\"] = df[\"pred_label\"].map({0: \"negative\", 1: \"positive\"})\n",
        "# Attach predictions to df\n",
        "df.to_csv(\"all_reviews_with_preds.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUxZOT7uWQAf",
        "outputId": "ad2bc67a-600b-4420-d5d8-b15ef270436a"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Inference complete in 28.03 seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.6.7 Product-level sentiment aggregation"
      ],
      "metadata": {
        "id": "_yUMhKe-bYYy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "performs product-level sentiment aggregation and saves a CSV of summary statistics that later pass to an LLM for review generation."
      ],
      "metadata": {
        "id": "wHDQ6bodWat6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"all_reviews_with_preds.csv\")\n",
        "# Aggregate Sentiment Stats by Product\n",
        "stats = (\n",
        "    df.groupby(\"name\")[\"pred_sentiment\"]\n",
        "      .value_counts(normalize=True)\n",
        "      .unstack(fill_value=0)\n",
        ")\n",
        "\n",
        "#Formatting to later use with LLM\n",
        "stats[\"review_count\"] = df.groupby(\"name\").size()\n",
        "stats.reset_index(inplace=True)\n",
        "stats.rename(columns={\"negative\":\"neg_pct\", \"positive\":\"pos_pct\"}, inplace=True)\n",
        "\n",
        "stats.to_csv(\"product_sentiment_stats.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "F9YetzQ_WbAz"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.6.8 Extract most helpful reviews for each product based on sentiment"
      ],
      "metadata": {
        "id": "1rviq_tVbiAv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For every product:\n",
        "\n",
        "Find the most helpful positive review\n",
        "\n",
        "Find the most helpful negative review\n",
        "And save them side by side for possible use in summaries or prompts to the LLM."
      ],
      "metadata": {
        "id": "Q5x-MkoIWlwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Finding the top negative and positive based of number of helpful column\n",
        "\n",
        "top_pos = df[df.pred_sentiment==\"positive\"].sort_values([\"name\",\"reviews.numHelpful\"], ascending=False).groupby(\"name\").first().reset_index()\n",
        "top_neg = df[df.pred_sentiment==\"negative\"].sort_values([\"name\",\"reviews.numHelpful\"], ascending=False).groupby(\"name\").first().reset_index()\n",
        "\n",
        "top_reviews = top_pos.merge(top_neg, on=\"name\", suffixes=(\"_pos\",\"_neg\"))\n",
        "top_reviews[[\"name\",\"reviews.text_pos\",\"reviews.text_neg\"]].to_csv(\"top_reviews_per_product.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "Hmhg9l6XWoOe"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This CSV is a perfect supplement to product_sentiment_stats.csv.\n",
        "can feed both into  LLM to write well-rounded summaries:\n",
        "\n",
        "Quantitative stats (pos_pct, neg_pct, review_count)\n",
        "\n",
        "Qualitative highlights (top helpful review examples)"
      ],
      "metadata": {
        "id": "mZfapj-9W1SS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now have\n",
        "\n",
        "Quantitative stats: percent of positive/negative reviews per product + review counts\n",
        "\n",
        "Qualitative review selection: Most helpful positive and negative review per product\n",
        "\n",
        "These two together give us a strong base for:\n",
        "\n",
        "Sentiment analysis\n",
        "\n",
        "Product summaries\n",
        "\n",
        "AI-generated overviews for shoppers or stakeholders"
      ],
      "metadata": {
        "id": "HXfIHYwsW8ma"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.7 LLM Model to create summary for each product"
      ],
      "metadata": {
        "id": "hXiow-h1cVc9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.7.1 Third Party LLM setup with Mistralai (HuggingFace)"
      ],
      "metadata": {
        "id": "v24jl4_0ey0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load sentiment stats and sample reviews\n",
        "stats = pd.read_csv(\"product_sentiment_stats.csv\")\n",
        "top_reviews = pd.read_csv(\"top_reviews_per_product.csv\")"
      ],
      "metadata": {
        "id": "6Ba5ZfvncxZf"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "login(token=\"*\")  # Hugging Face token (removed for here)\n"
      ],
      "metadata": {
        "id": "QHnTonvAdGE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.7.2 Model & Tokenizer Setup and Inference Pipeline"
      ],
      "metadata": {
        "id": "4VPszspnfGEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "\n",
        "model_id = \"mistralai/Mistral-7B-Instruct-v0.1\"  # gated model with access\n",
        "\n",
        "# Loads the tokenizer associated with the model (tokenizes input text into IDs).\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, use_auth_token=True)\n",
        "\n",
        "'''\n",
        "Loads the causal language model:\n",
        "\n",
        "torch_dtype=torch.float16: reduces memory usage (important for 7B models).\n",
        "\n",
        "device_map=\"auto\": automatically distributes the model across available GPU(s) or CPU.\n",
        "\n",
        "use_auth_token=True: required due to restricted access.\n",
        "'''\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16, device_map=\"auto\", use_auth_token=True)\n",
        "\n",
        "'''\n",
        "max_new_tokens=150: limit the output to 150 new tokens (words/punctuation).\n",
        "\n",
        "temperature=0.7: controls randomness. Lower is more deterministic; 0.7 is moderately creative.\n",
        "\n",
        "device_map=\"auto\" again ensures the model uses GPU if available.\n",
        "'''\n",
        "generator = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=150,\n",
        "    temperature=0.7,\n",
        "    device_map=\"auto\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "a7E4pHY3dnxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.7.3 Generate summaries per product using sentiment stats and top reviews with LLM\n"
      ],
      "metadata": {
        "id": "Cb8q9Ja3gEP2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Automatically generate short product summaries using an LLM based on:\n",
        "\n",
        "Sentiment distribution per product.\n",
        "\n",
        "Most helpful positive and negative reviews."
      ],
      "metadata": {
        "id": "Sj5aTDtugZCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "stats = pd.read_csv(\"product_sentiment_stats.csv\")\n",
        "reviews = pd.read_csv(\"top_reviews_per_product.csv\")\n",
        "\n",
        "PROMPT = \"\"\"\n",
        "Product: {name}\n",
        "Reviews: {review_count}, 👍 {pos_pct:.0%}, 👎 {neg_pct:.0%}\n",
        "Top Positive: \"{text_pos}\"\n",
        "Top Negative: \"{text_neg}\"\n",
        "\n",
        "Write a concise 1–2 sentence summary: key strength, main issue, and overall recommendation.\n",
        "\"\"\"\n",
        "\n",
        "summaries = []\n",
        "for _, r in stats.iterrows():\n",
        "    revs = reviews[reviews[\"name\"] == r[\"name\"]]\n",
        "    if revs.empty:\n",
        "      continue\n",
        "\n",
        "    rev = revs.iloc[0]\n",
        "    prompt = PROMPT.format(\n",
        "        name=r[\"name\"],\n",
        "        review_count=r[\"review_count\"],\n",
        "        pos_pct=r[\"pos_pct\"],\n",
        "        neg_pct=r[\"neg_pct\"],\n",
        "        text_pos=rev[\"reviews.text_pos\"],\n",
        "        text_neg=rev[\"reviews.text_neg\"],\n",
        "    )\n",
        "    out = generator(prompt)[0][\"generated_text\"].strip()\n",
        "    summaries.append({\"name\": r[\"name\"], \"summary\": out})\n",
        "\n",
        "pd.DataFrame(summaries).to_csv(\"product_summaries.csv\", index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "QvtU8AGcdurm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}